{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ME5: Simple Linear Regression on COVID-19 Datasets\n",
    "\n",
    "\n",
    "#### Learning the data using visualization and simple linear regression\n",
    "\n",
    "1. First, run the examples and understand the ML process and be familir with Python package functions for simple linear regression. \n",
    "\n",
    "2. Apply exploratory data analysis and simple regression on COVID-19 dataset(s). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write your name and your collaborators if any.\n",
    "\n",
    "-\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Recap of regression model evaluation\n",
    "\n",
    "#### Regression modeling\n",
    "\n",
    "Cross validation:\n",
    "- https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "Model evaluation:\n",
    "- https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Linear regression:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "Logistic regression (In general, logistic regressions are used for classification):\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "#### Model evaluation metrics for regression models\n",
    "\n",
    "First, Let's review model evaluation metrics for regression models. \n",
    "\n",
    "Evaluation metrics for classification problems, such as **accuracy**, are not useful for regression problems. Instead, we need evaluation metrics designed for comparing continuous values.\n",
    "\n",
    "Let's create some example numeric predictions, and calculate **three common evaluation metrics** for regression problems:\n",
    "\n",
    "\n",
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
    "\n",
    "Comparing these metrics:\n",
    "\n",
    "- **MAE** is the easiest to understand, because it's the average error.\n",
    "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors.\n",
    "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "#### The R2 (\"r-squared\") Regression Score\n",
    "\n",
    "- Measures how well a prediction model for regression fits the given data.\n",
    "\n",
    "- The score is between 0 and 1:\n",
    "\n",
    "     - A value of 0 corresponds to a constant model that predicts the mean value of all training target values.\n",
    "\n",
    "     - A value of 1 corresponds to perfect prediction\n",
    "\n",
    "- Also known as \"coefficient of determination\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 - Simple Linear Regression Examples\n",
    "\n",
    "Two linear regression models:\n",
    "\n",
    "(1) A real dataset: each data tuple has one attribute in X and its corresponding y value. \n",
    "\n",
    "(2) A synthetic dataset: each data tuple has two attributes in X and its corresponding y value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (1) Simple Linear Regression Example - one attribute in X\n",
    "\n",
    "Simple linear regression is an approach for predicting a **quantitative response** using a **single feature** (or \"predictor\" or \"input variable\"). It takes the following form:\n",
    "\n",
    "$y = \\theta_0x_0 + \\theta_1x_1$\n",
    "\n",
    "- $y$ is the response\n",
    "- $x_0 = 1$\n",
    "- $x_1$ is the attribute\n",
    "- $\\theta_0$ is the coeffficient for $x_0$ (intercept)\n",
    "- $\\theta_1$ is the coefficient for $x_1$\n",
    "\n",
    "The $\\theta$ values are called the **model coefficients**. These values are \"learned\" during the model fitting step using the \"least squares\" criterion. Then, the fitted model can be used to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the code and observe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The code expects the data files to be located in the current directory. Fetch the files in datasets/lifesat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function just merges the OECD's life satisfaction data and the IMF's GDP per capita data. It's a bit too long and boring and it's not specific to Machine Learning, which is why I left it out of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
    "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "    \n",
    "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
    "                                  left_index=True, right_index=True)\n",
    "    \n",
    "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
    "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
    "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
    "    \n",
    "    return full_country_stats[['GDP per capita', 'Life satisfaction']].iloc[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datapath = os.path.join(\"datasets\", \"lifesat\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "import urllib\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "os.makedirs(datapath, exist_ok=True)\n",
    "\n",
    "for filename in (\"oecd_bli_2015.csv\", \"gdp_per_capita.csv\"):\n",
    "    print(\"Downloading\", filename)\n",
    "    url = DOWNLOAD_ROOT + \"datasets/lifesat/\" + filename\n",
    "    urllib.request.urlretrieve(url, datapath + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code example of load the data and prepared the data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "\n",
    "# Load the data\n",
    "oecd_bli = pd.read_csv(datapath + \"oecd_bli_2015.csv\", thousands=',')\n",
    "gdp_per_capita = pd.read_csv(datapath + \"gdp_per_capita.csv\",thousands=',',delimiter='\\t',\n",
    "                             encoding='latin1', na_values=\"n/a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the data and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures directly within Jupyter\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "\n",
    "X = np.c_[country_stats['GDP per capita']]\n",
    "y = np.c_[country_stats['Life satisfaction']]\n",
    "\n",
    "# Visualize the data\n",
    "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Create a simple linear regression \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a simple linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model (we use all data for training --> Later we will divide the data into training data and testing data)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.coef_)\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict y for a new X value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction for Cyprus \n",
    "# new data value 22587 for Cyprus's GDP per capita\n",
    "\n",
    "X_new = [[22587]]\n",
    "\n",
    "y_predict = model.predict(X_new)\n",
    "\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a scatter graph together with the regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatterplot \n",
    "plt.scatter(X, y, c='red', label='observed')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.xlabel('GDP per capita')\n",
    "plt.ylabel('Life satisfaction')\n",
    "plt.title('Regression')\n",
    "\n",
    "# plot the regression function\n",
    "plt.plot(X, model.predict(X), c='green', label='fitted', linewidth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preparing X and y using pandas\n",
    "- We already did this process above\n",
    "- scikit-learn expects X (feature matrix) and y (response vector) to be NumPy arrays.\n",
    "- However, pandas is built on top of NumPy.\n",
    "- Thus, X can be a pandas DataFrame and y can be a pandas Series!\n",
    "\n",
    "See more details about Pandas Series and Numpy\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Splitting X and y into training and testing sets\n",
    "\n",
    "We are using the same data that is stored X, y above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing (test data size 30%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                        test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Linear regression in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate a simple linear regression model \n",
    "linreg = LinearRegression()\n",
    "\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Making predictions for testing data\n",
    "\n",
    "Use X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linreg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Computing the RMSE \n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. K Cross Validation and Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into 3 folds \n",
    "\n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "print(kf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up a testbed using KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a new simple linear regressor\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Conduct 3-fold cross validation\n",
    "\n",
    "rmse = []\n",
    "r2 = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    \n",
    "    rmse.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    r2.append(metrics.r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(rmse)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Curve\n",
    "\n",
    "Check the details for learning curve\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "    \n",
    "# evaluate the training and testing and retrieve the information of model performance. \n",
    "\n",
    "train_sizes = np.linspace(0.2, 0.8, 5)\n",
    "\n",
    "\n",
    "train_sizes, train_mse, test_mse = learning_curve(linreg, X, y, \n",
    "                                    train_sizes = train_sizes, \n",
    "                                    scoring='neg_root_mean_squared_error', \n",
    "                                    cv=3, shuffle=True)\n",
    "\n",
    "train_scores = np.sqrt(np.abs(train_mse))\n",
    "test_scores = np.sqrt(np.abs(test_mse))\n",
    "\n",
    "print(train_scores)\n",
    "print(test_scores)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('A learning curve for a simple linear regression')\n",
    "ax.set_xlabel(\"Training examples\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Multivariate Linear Regression on a Synthetic Dataset\n",
    "\n",
    "Simple linear regression can easily be extended to include multiple features. This is called **multiple linear regression**:\n",
    "### Form of linear regression\n",
    "\n",
    "$y = \\theta_0x_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_nx_n$\n",
    "\n",
    "- $y$ is the response\n",
    "- $x_0 = 1$\n",
    "- $x_1, x_2, ..., x_n$ are attributes\n",
    "- $\\theta_0$ is the coeffficient for $x_0$ (intercept)\n",
    "- $\\theta_1$ is the coefficient for $x_1$ (the first attribute)\n",
    "- $\\theta_n$ is the coefficient for $x_n$ (the nth attribute)\n",
    "\n",
    "The $\\theta$ values are called the **model coefficients**. These values are \"learned\" during the model fitting step using the \"least squares\" criterion. Then, the fitted model can be used to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a synthetic data\n",
    "- Each data tuple has 4 attributes in X and its corresponding y value. \n",
    "\n",
    "- For generating a random dataset of n=1000 samples for regression modeling, see the detail:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic dataset for classification (binary)\n",
    "from sklearn.datasets import make_regression, make_blobs\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Sample binary classification problem with two informative features')\n",
    "\n",
    "# generate X values and y values\n",
    "# check make_regression() for other parameters\n",
    "X, y = make_regression(n_samples = 1000, n_features=5,\n",
    "                                n_informative=2,n_targets=1,\n",
    "                                noise=0.0, random_state=0)\n",
    "\n",
    "# Warning!!! scatter() function can handle only 2 dimensions\n",
    "# Hence you pick two attributes only and plot the data\n",
    "plt.scatter(X[:, 0], X[:, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing (test data size 30%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                        test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a inear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate a simple linear regression model \n",
    "linreg = LinearRegression()\n",
    "\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check RMSE of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into 3 folds \n",
    "\n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "print(kf) \n",
    "\n",
    "# Let's create a new simple linear regressor\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Conduct 3-fold cross validation\n",
    "\n",
    "rmse = []\n",
    "r2 = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    \n",
    "    rmse.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    r2.append(metrics.r2_score(y_test, y_pred))\n",
    "\n",
    "print(rmse, '\\n Average RMSE:', np.mean(rmse))\n",
    "print(r2, '\\n Average R2:', np.mean(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "    \n",
    "# evaluate the training and testing and retrieve the information of model performance. \n",
    "\n",
    "train_sizes = np.linspace(0.2, 0.8, 50)\n",
    "\n",
    "train_sizes, train_mse, test_mse = learning_curve(linreg, X, y, \n",
    "                                    train_sizes = train_sizes, \n",
    "                                    scoring='neg_root_mean_squared_error', \n",
    "                                    cv=3, shuffle=True)\n",
    "\n",
    "train_scores = np.sqrt(np.abs(train_mse))\n",
    "test_scores = np.sqrt(np.abs(test_mse))\n",
    "\n",
    "#print(train_scores)\n",
    "#print(test_scores)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# Plot learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('A learning curve for a simple linear regression')\n",
    "ax.set_xlabel(\"Training examples\")\n",
    "ax.set_ylabel(\"Score (RMSE)\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 1: Explore insight of the data using simple regression\n",
    "\n",
    "The following Git repository is for the COVID-19 visual dashboard operated by the Johns Hopkins University Center for Systems Science and Engineering:\n",
    "https://github.com/CSSEGISandData/COVID-19\n",
    "\n",
    "Read the information on the dashboard and check the datasets details\n",
    "\n",
    "Datasets are located in a folder: csse_covid_19_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Select day for X and # of cases for y from either US only or all data.\n",
    "\n",
    "   1.1 (optional) If you find any missing data or/and invalid data in the selected attributes you would like to work on, apply tools to handle these data. \n",
    "\n",
    "2. Conduct preliminary exploratory data analysis on the selected data and visualize the data. This may include the following but not limited:\n",
    "\n",
    "    - The five number summary, box plots, histograms, or/and scatter plots. \n",
    "\n",
    "3. Display simple linear regression function with a scatter plot\n",
    "    --> You will see the data does not follow a simple linear function. \n",
    "   \n",
    "4. Create a logistic regression function instead of a simple linear regression. See the web resources below:\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    - This time draw a scatter plot of the data together with the logistic regression function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Load data\n",
    "\n",
    "- Examples in the next three cells show how to obtain data from web resources and load the data to DataFrame.\n",
    "\n",
    "- You should modify the code for the datasets and data attributes you are interested. \n",
    "\n",
    "##### Obtain data from the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "datapath = os.path.join(\"csse_covid_19_data\", \"csse_covid_19_data\", \"\")\n",
    "\n",
    "import urllib\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\"\n",
    "os.makedirs(datapath, exist_ok=True)\n",
    "for filename in (\"time_series_covid19_confirmed_US.csv\",):\n",
    "    print(\"Downloading\", filename)\n",
    "    url = DOWNLOAD_ROOT + \"csse_covid_19_data/csse_covid_19_data/\" + filename\n",
    "    urllib.request.urlretrieve(DOWNLOAD_ROOT, datapath + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_confirmed_timeseries = pd.read_csv(datapath + \"time_series_covid19_confirmed_US.csv\")\n",
    "wash_cases = us_confirmed_timeseries.loc[us_confirmed_timeseries[\"Province_State\"] == \"Washington\"]\n",
    "wash_cases = wash_cases.drop(columns=['UID', 'iso2', 'iso3', 'FIPS', 'Province_State', 'Country_Region', 'Lat', 'Long_'\n",
    ", 'code3', 'Combined_Key', 'Admin2'])\n",
    "cases_by_date = wash_cases.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'date':cases_by_date.index, 'cases':cases_by_date.values})\n",
    "df['day_number'] = df.index\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) A linear regression model\n",
    "\n",
    "- Train a linear regression model\n",
    "- Visualize the model with scatter plot\n",
    "- Conduct k=10 cross validation and show the result\n",
    "- Display learning curve based on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) A logistic regression model\n",
    "\n",
    "- Train a logistic regression model\n",
    "- Visualize the model with scatter plot\n",
    "- Conduct k=10 cross validation and show the result\n",
    "- Display learning curve based on training data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Write a summary of what you find from the data\n",
    "\n",
    "- Submit your summary to Canvas\n",
    "- Provide a link to your Git repo of the assignment. \n",
    "\n",
    "Logistic regression is better than linear regression but still it results in a low score. \n",
    "\n",
    "The data shown above tracks the number of COVID-19 Cases in Washington State. The data shows little change until day 40 where the cases start to increase exponentially. Due to this, a linear model is insufficiant. Furthermore, a logistic model works much better. It should be noted that the number of cases is changing due to external factors such as social distancing and really cannot be modeled based on either of these models long term.\n",
    "\n",
    "Note to reader: These Cross Validation Scores were calculated on 4/20/2022. Since the csv file is updated frequently as new data comes in and the data in this notebook changes as a result, I do not expect the scores to remain the same. If we have a true flattening of the curve the linear model will perform better in the new part and the logistic model will perform worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
