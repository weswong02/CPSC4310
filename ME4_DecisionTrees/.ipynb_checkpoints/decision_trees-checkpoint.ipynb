{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ME4: Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborators\n",
    "\n",
    "Notes: This homework can be done individually or by a troup of two. If this is done by a group, please write the names of students who work together. Make sure that each individual makes own submission(s). \n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0\n",
    "\n",
    "- Read each cell of the examples below, run and check the outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix simple example 1 - binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true1 = [1, 0, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred1 = [1, 1, 0, 1, 1, 0, 1, 1, 1]\n",
    "\n",
    "\n",
    "confusion_mat1 = confusion_matrix(y_true1, y_pred1)\n",
    "\n",
    "print(confusion_mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "target_names2 = ['Class-0', 'Class-1']\n",
    "\n",
    "result_metrics = classification_report(y_true1, y_pred1, target_names=target_names2)\n",
    "\n",
    "print(result_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix simple example 2 - multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true2 = [1, 0, 0, 2, 1, 0, 3, 3, 3]\n",
    "y_pred2 = [1, 1, 0, 2, 1, 0, 1, 3, 3]\n",
    "\n",
    "confusion_mat2 = confusion_matrix(y_true2, y_pred2)\n",
    "print(confusion_mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "target_names2 = ['Class-0', 'Class-1', 'Class-2', 'Class-3']\n",
    "\n",
    "result_metrics2 = classification_report(y_true2, y_pred2, target_names=target_names2)\n",
    "\n",
    "print(result_metrics2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "- dataset: iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"images/iris.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data visualization of the iris dataset before we start training and testing a model\n",
    "\n",
    "- iris.csv is stored in a local folder 'data'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# read data from CSV file to dataframe\n",
    "iris = pd.read_csv('./data/iris.csv')\n",
    "\n",
    "# make sure you understand the type of the object\n",
    "print(type(iris))\n",
    "\n",
    "# check the top five and the botoom five data tuples\n",
    "print(iris.head())\n",
    "print(iris.tail())\n",
    "\n",
    "# scatter matrix plot\n",
    "pd.plotting.scatter_matrix(iris);\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "- Read the details of decision tree classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "- Check out the difference between model parameters and hyper parameters:\n",
    "\n",
    "https://towardsdatascience.com/model-parameters-and-hyperparameters-in-machine-learning-what-is-the-difference-702d30970f6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple example of DT modeling\n",
    "\n",
    "- We first start the modeling without k-cross validation here but show step-by-step code segments how to train a model and test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "- For the following code, we use sklearn.datasets package for loading a dataset instead of reading a data file stored on a local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# make sure that you understand the type of the object\n",
    "print(type(iris)) \n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = iris.data # sepal length and width, petal length and width\n",
    "y = iris.target\n",
    "\n",
    "#print(X)\n",
    "\n",
    "# split the data 70% for training, 30% for test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Learing using training data\n",
    "\n",
    "- use Gini index measure \n",
    "\n",
    "*** Notes: you can also use gain information (entropy) measure by setting criterion=\"entropy\" in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, criterion='gini')\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "### Evaluating the model using testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_clf.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a confusion matrix\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "\n",
    "target_names = iris.target_names\n",
    "\n",
    "result_metrics = classification_report(y_test, y_pred, target_names=target_names)\n",
    "\n",
    "print(result_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# you can access each class's metrics from result_metrics\n",
    "\n",
    "# you can access each class's metrics from result_metrics\n",
    "# output_dict should be set to True\n",
    "result_metrics_dict = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "\n",
    "print(result_metrics_dict)\n",
    "\n",
    "# an example that shows how to access the value of precision metric of class 'setosa'\n",
    "print(result_metrics_dict['setosa']['precision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw a decision tree\n",
    "\n",
    "- You may need to install graphviz package!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file=os.path.join(IMAGES_PATH, \"iris_tree.dot\"),\n",
    "        feature_names=iris.feature_names,\n",
    "        class_names=iris.target_names,\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n",
    "\n",
    "Source.from_file(os.path.join(IMAGES_PATH, \"iris_tree.dot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important features from a decision tree using gini index\n",
    "\n",
    "- Decision tree classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html#classification\n",
    "\n",
    "- Metrics\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot important features\n",
    "def plot_feature_importances(clf, feature_names):\n",
    "    c_features = len(feature_names)\n",
    "    plt.barh(range(c_features), clf.feature_importances_)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature name\")\n",
    "    plt.yticks(np.arange(c_features), feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = DecisionTreeClassifier(criterion='gini').fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of DT classifier on training set: {:.2f}'\n",
    "     .format(clf1.score(X_train, y_train)))\n",
    "print('Accuracy of DT classifier on test set: {:.2f}'\n",
    "     .format(clf1.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=60)\n",
    "\n",
    "# call the function above\n",
    "plot_feature_importances(clf1, iris.feature_names)\n",
    "plt.show()\n",
    "\n",
    "print('Feature importances: {}'.format(tree_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of DT classifier on training set: {:.2f}'\n",
    "     .format(clf2.score(X_train, y_train)))\n",
    "print('Accuracy of DT classifier on test set: {:.2f}'\n",
    "     .format(clf2.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4), dpi=60)\n",
    "\n",
    "# call the function above\n",
    "plot_feature_importances(clf2, iris.feature_names)\n",
    "plt.show()\n",
    "\n",
    "print('Feature importances: {}'.format(tree_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Cross Validation\n",
    "\n",
    "- using KFold function with freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold # import k-fold validation\n",
    "\n",
    "kf = KFold(n_splits=3, random_state=None, shuffle=True) # Define the split - into 2 folds \n",
    "\n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "print(kf) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying k-Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    target_names = iris.target_names\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting classes and class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class0 (setona) \n",
    "prob = tree_clf.predict_proba([[5.0, 3.4, 1.3, 0.2]]) \n",
    "\n",
    "# check predictions for different samples\n",
    "# Class1 (versicolor)\n",
    "#prob = tree_clf.predict_proba([[7.1, 3.1, 4.8, 1.4]])\n",
    "\n",
    "# Class2 (virginica)\n",
    "#prob = tree_clf.predict_proba([[6.4, 2.7, 4.9, 1.8]])\n",
    "\n",
    "print(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict class1 (versicolor)\n",
    "predicted = tree_clf.predict([[5.0, 3.4, 1.3, 0.2]])\n",
    "\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ME4\n",
    "\n",
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct decision trees\n",
    "\n",
    "#### 1. Construct  a decision tree using the following parameters\n",
    "\n",
    "- Use information gain (entropy) measure\n",
    "- Apply k=10 cross validation and print a summary of statistics (performance evaluation) for each fold\n",
    "\n",
    "\n",
    "#### 2. Compare the performance results with those of the decision tree using Gini index measure in the above example\n",
    "\n",
    "#### 3. For both trees, change the following parameters and observe the changes:\n",
    "\n",
    "- The depth of tree: currently max_depth=2 in the model training step. Change the depth 3, 4, 5 and check if this affects the overall results. \n",
    "\n",
    "- The k value for cross validation is currently set to 3. Change k value, k = 5, 7, 10 and check if this affects the overall results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "1. See DT examples at:\n",
    "    \n",
    "https://www.kaggle.com/dmilla/introduction-to-decision-trees-titanic-dataset\n",
    "\n",
    "2. Discuss about different ways to handle the following types of data for decision tree classification. \n",
    "\n",
    "    - text data (strings): in the case a dataset includes non-numerical data. \n",
    "\n",
    "    - continuous data like age, weight, income, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission(s): Each individual student should make own submission. \n",
    "\n",
    "- Upload the notebook on your Git repo and provide an URL link in your summar. \n",
    "\n",
    "- Submit your summar to Canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {
   "height": "309px",
   "width": "468px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
