{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ME6 Linear Regression with Gradient Descent\n",
    "\n",
    "Write your name and your collaborators if any. \n",
    "\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0\n",
    "\n",
    "- Read and run each cell of the given examples: (1) synthetic dataset (2) crime dataset\n",
    "\n",
    "- Understand the results. In particular, see how feature normalization affects on ridges regression and how the model performance changes when varying alpha parameter values are used in both ridge regression and Lasso regression. \n",
    "\n",
    "### Linear models for regression\n",
    "\n",
    "- Visit sklearn web site:\n",
    "   - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "\n",
    "- Please also check model evaluation metrics for regression:\n",
    "\n",
    "    - https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "    - ME5 Simple Linear Regression shows evaluation metrics for regression in detail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing X and Y using pandas\n",
    "- We already did this process above\n",
    "- scikit-learn expects X (feature matrix) and Y (response vector) to be NumPy arrays.\n",
    "- However, pandas is built on top of NumPy.\n",
    "- Thus, X can be a pandas DataFrame and y can be a pandas Series!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1: Synthetic random data points\n",
    "\n",
    "- One single attribute in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# synthetic dataset for simple regression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Sample regression problem with one input variable')\n",
    "X_R1, y_R1 = make_regression(n_samples = 100, n_features=1,\n",
    "                             n_informative=1, bias = 150.0,\n",
    "                             noise = 30, random_state=0)\n",
    "\n",
    "plt.scatter(X_R1, y_R1, marker= 'o', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression on synthetic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_R1, y_R1, random_state=0)\n",
    "\n",
    "linreg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression model coefficient and intercept values \\& performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('linear model intercept (b): {:.3f}'.format(linreg.intercept_))\n",
    "print('linear model coeff (w): {}'.format(linreg.coef_))\n",
    "\n",
    "# train data R2\n",
    "print('R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
    "# test data R2\n",
    "print('R-squared score (test): {:.3f}'.format(linreg.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set and print RMSE\n",
    "y_pred = linreg.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression cost optimization\n",
    "\n",
    "First, we add 1 for x0 value to each data tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), X_R1]  # add x0 = 1 to each data tuple\n",
    "y_b = y_R1.reshape(100, 1)\n",
    "\n",
    "print(X_b.shape, '\\n', y_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain the exact theta vector using close form\n",
    "\n",
    "<img src=\"images/cf.png\" style=\"width: 200px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_R1)\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain theta using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "alpha = 0.01\n",
    "\n",
    "# number of iterations\n",
    "n_iteration = 100\n",
    "\n",
    "# the number of data points\n",
    "n = 100\n",
    "\n",
    "# random initialization to theta. \n",
    "# Return samples (2 values for theta0 for x0 and theta1 for x1) \n",
    "# from the “standard normal” distribution.\n",
    "theta = np.random.randn(2, 1)\n",
    "\n",
    "print('initial theta: \\n', theta, theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the process of gradient descent\n",
    "for iteration in range(n_iteration):\n",
    "    gradient = (1/n) * X_b.T.dot(X_b.dot(theta) - y_b)\n",
    "    theta = theta - alpha*gradient\n",
    "    \n",
    "print('best theta: \\n', theta)\n",
    "\n",
    "# we will need to tune with learning rate alpha and # of iterations\n",
    "# to find out the optimal theta value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot the linear model with scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.scatter(X_R1, y_R1, marker= 'o', s=50, alpha=0.8)\n",
    "plt.plot(X_R1, linreg.coef_ * X_R1 + linreg.intercept_, 'r-')\n",
    "plt.title('Least-squares linear regression')\n",
    "plt.xlabel('Feature value (x)')\n",
    "plt.ylabel('Target value (y)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2: crime dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crime_dataset():\n",
    "    # Communities and Crime dataset for regression\n",
    "    # https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized\n",
    "\n",
    "    # na_values='?'\n",
    "    crime = pd.read_csv('./data/CommViolPredUnnormalizedData.csv', na_values='?')\n",
    "    # remove features with poor coverage or lower relevance, and keep ViolentCrimesPerPop target column\n",
    "    columns_to_keep = [5, 6] + list(range(11,26)) + list(range(32, 103)) + [145]  \n",
    "    \n",
    "    crime = crime.iloc[:, columns_to_keep]\n",
    "    crime = crime.dropna()\n",
    "    \n",
    "    X_crime = crime.iloc[:, 0:88]\n",
    "    y_crime = crime['ViolentCrimesPerPop']\n",
    "\n",
    "    return (X_crime, y_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communities and Crime dataset\n",
    "(X_crime, y_crime) = load_crime_dataset()\n",
    "\n",
    "#print(X_crime.head())\n",
    "#print(y_crime.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_crime.shape, '\\n', y_crime.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[np.ones((1994, 1)), X_crime]\n",
    "X.shape\n",
    "# now there are 89 attributes including x0 and 88 data attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = y_crime.values.reshape(1994, 1)\n",
    "\n",
    "print(y.shape,'\\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.05  # learning rate\n",
    "n_iterations = 10 # number of total iterations\n",
    "n = 1994 # the number of data\n",
    "\n",
    "theta = np.random.randn(89, 1)  # random initialization\n",
    "\n",
    "print(theta.shape, '\\n', theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(n_iterations):\n",
    "    gradient = (1/n) * X.T.dot(X.dot(theta) - y)\n",
    "    theta = theta - eta * gradient\n",
    "    \n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_crime.iloc[:1, 0:88]\n",
    "X_new_b = np.c_[np.ones((1, 1)), X_new] \n",
    "y_new = y_crime[0]\n",
    "\n",
    "y_predict = X_new_b.dot(theta)\n",
    "\n",
    "print(y_new, '\\n', y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression on crime dataset (without regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime, random_state=0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('Crime dataset')\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "\n",
    "print('linear model intercept: {}'.format(linreg.intercept_))\n",
    "print('linear model coeff:\\n{}'.format(linreg.coef_))\n",
    "\n",
    "print('Number of non-zero features: {}'.format(np.sum(linreg.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression (regularized regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime, random_state=0)\n",
    "\n",
    "linridge = Ridge(alpha=20.0).fit(X_train, y_train)\n",
    "\n",
    "print('Crime dataset')\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "\n",
    "print('ridge regression linear model intercept: {}'.format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'.format(linridge.coef_))\n",
    "\n",
    "print('Number of non-zero features: {}'.format(np.sum(linridge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression with feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linridge = Ridge(alpha=20.0).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Crime dataset')\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test_scaled, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "\n",
    "print('ridge regression linear model intercept: {}'.format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'.format(linridge.coef_))\n",
    "\n",
    "print('Number of non-zero features: {}'.format(np.sum(linridge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression with regularization parameter: alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in [0, 1, 10, 20, 50, 100, 1000]:\n",
    "    linridge = Ridge(alpha = this_alpha).fit(X_train_scaled, y_train)\n",
    "    r2_train = linridge.score(X_train_scaled, y_train)\n",
    "    r2_test = linridge.score(X_test_scaled, y_test)\n",
    "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 1.0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
    "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linlasso = Lasso(alpha=2.0, max_iter = 10000).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Crime dataset')\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test_scaled, y_test)))\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "print('RMSE: {:.3f}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "    \n",
    "print('lasso regression linear model intercept: {}'.format(linlasso.intercept_))\n",
    "print('lasso regression linear model coeff:\\n{}'.format(linlasso.coef_))\n",
    "\n",
    "print('Non-zero features: {}'.format(np.sum(linlasso.coef_ != 0)))\n",
    " \n",
    "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
    "for e in sorted (list(zip(list(X_crime), linlasso.coef_)),\n",
    "                key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso regression with regularization parameter: alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lasso regression: effect of alpha regularization\\n\\\n",
    "parameter on number of features kept in final model\\n')\n",
    "\n",
    "for alpha in [0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
    "    linlasso = Lasso(alpha, max_iter = 10000).fit(X_train_scaled, y_train)\n",
    "    r2_train = linlasso.score(X_train_scaled, y_train)\n",
    "    r2_test = linlasso.score(X_test_scaled, y_test)\n",
    "    \n",
    "    print('Alpha = {:.2f}\\nFeatures kept: {}, r-squared training: {:.2f}, \\\n",
    "r-squared test: {:.2f}\\n'\n",
    "         .format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Linear Regression Modeling on Breast Cancer dataset\n",
    "\n",
    "a. Obtain the exact theta vector using closed form.\n",
    "\n",
    "b. Obtain the optimal theta vector using Gradient Descent.\n",
    "\n",
    "c. Apply the following regression model on breast cancer dataset:\n",
    "\n",
    "    (1) Linear regression without regularization\n",
    "\n",
    "    (2) Ridge regression \n",
    "\n",
    "    (3) Ridge regression with feature normalization\n",
    "\n",
    "    (4) Ridge regression with regularization parameter: alpha\n",
    "\n",
    "    (5) Lasso regression\n",
    "\n",
    "    (6) Lasso regression with regularization parameter: alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloading: Breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Breast cancer dataset for classification\n",
    "cancer = load_breast_cancer()\n",
    "(X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)\n",
    "\n",
    "print(cancer.feature_names)\n",
    "print(y_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. (Closed form)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. (Gradient descent). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Linear regression without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Ridge regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Ridge regression with feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Ridge regression with regularization parameter: alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Lasso regression with regularization parameter: alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "- Submit your summary to Canvas\n",
    "- Provide a link to your Git repo of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
